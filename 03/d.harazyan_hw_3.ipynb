{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html as lhtml                         # Непосредственно для парсинга.\n",
    "import requests                                        # Для получения html кода сайта.\n",
    "from multiprocessing.dummy import Pool as ThreadPool   # Для реализации параллельной обкачки.\n",
    "from multiprocessing import Lock, Value                # Для логгирования.\n",
    "from math import ceil                                  # Для округления вверх.\n",
    "from tqdm.notebook import tqdm                         # Для визуализации прогресса итерации по генератору.\n",
    "import time                                            # Для ожидания окончания работы в  get_page().\n",
    "from multiprocessing import Lock                       # Для логгирования.\n",
    "import functools                                       # Для декоратора.\n",
    "\n",
    "import numpy as np  # Для дебага, чтобы получать произвольные url'ы.\n",
    "import random       # Для дебага, чтобы получать произвольные url'ы.\n",
    "\n",
    "import pandas as pd # Непосредственно для формирования *.csv файла.\n",
    "pd.options.display.max_columns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.txt', 'r') as f:\n",
    "    authors_id = list(map(int, f.read().split('\\n')[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "way = '//div[@class=\"rd-listing-product-item rd-listing-product-item_size- rd-listing-product-item_type-\"]/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url, n_attempts=5, t_sleep=1, **kwargs):\n",
    "    r_get = requests.get(url, **kwargs)\n",
    "    n_attempts -= 1\n",
    "    \n",
    "    while n_attempts > 0 and not r_get.ok:\n",
    "            time.sleep(t_sleep)\n",
    "            r_get = requests.get(url, **kwargs)\n",
    "            n_attempts -= 1\n",
    "    \n",
    "    if n_attempts >= 0:\n",
    "        return r_get   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exception_counter(func):\n",
    "    \n",
    "    mutex = Lock()\n",
    "    \n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **argv):   \n",
    "        \n",
    "        if not hasattr(wrapper, 'ex_count'):\n",
    "            setattr(wrapper, 'ex_count', 0)\n",
    "            \n",
    "        try:\n",
    "            result = func(*args, **argv)\n",
    "        \n",
    "        except:\n",
    "            wrapper.ex_count += 1\n",
    "            return \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@exception_counter\n",
    "def get_url(author):\n",
    "    \n",
    "    url_for_download = []\n",
    "\n",
    "    page_url = \"https://www.respublica.ru/authors/\" + str(author)\n",
    "    html = get_page(page_url)\n",
    "    if html == None:\n",
    "        return\n",
    "    tree = lhtml.fromstring(html.text)\n",
    "    books_per_page = tree.xpath('//span[@class=\"rd-listing-count__current\"]')\n",
    "    if books_per_page:\n",
    "        books_per_page = int(books_per_page[0].text.split()[-1])\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    all_page_nums = ceil(int(tree.xpath('//span[@class=\"rd-listing-count__total\"]')[0].text) / books_per_page)\n",
    "\n",
    "    for page_num in range(all_page_nums):\n",
    "        \n",
    "        page_url = \"https://www.respublica.ru/authors/\" + str(author)\n",
    "        html = get_page(page_url, params={'page': page_num})\n",
    "        if html == None:\n",
    "            return        \n",
    "        tree = lhtml.fromstring(html.text)\n",
    "        all_book_on_page = tree.xpath(way)\n",
    "\n",
    "        for book in all_book_on_page:\n",
    "            url_for_download.append(\"https://www.respublica.ru\"+book.attrib['href'])\n",
    "    return url_for_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@exception_counter\n",
    "def get_url(author):\n",
    "    \n",
    "    url_for_download = []\n",
    "\n",
    "    page_url = \"https://www.respublica.ru/authors/\" + str(author)\n",
    "    html = get_page(page_url)\n",
    "    if html == None:\n",
    "        return\n",
    "    tree = lhtml.fromstring(html.text)\n",
    "    all_book_on_page = True\n",
    "    page_num = 0\n",
    "    \n",
    "    while all_book_on_page:\n",
    "        \n",
    "        html = get_page(page_url, params={'page': page_num})\n",
    "        if html == None:\n",
    "            return        \n",
    "        \n",
    "        tree = lhtml.fromstring(html.text)\n",
    "        all_book_on_page = tree.xpath(way)\n",
    "\n",
    "        for book in all_book_on_page:\n",
    "            url_for_download.append(\"https://www.respublica.ru\"+book.attrib['href'])\n",
    "            \n",
    "        page_num += 1\n",
    "        \n",
    "    return url_for_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with ThreadPool(10) as pool:\n",
    "    authors_book_urls = pool.map(get_url, authors_id)\n",
    "pool.join()\n",
    "\n",
    "url_history_for_download = [url for sub_list in authors_book_urls for url in sub_list]\n",
    "\n",
    "print(\"%i\" % get_url.ex_count, \"pages failed to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_history_for_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def get_site(url):    \n",
    "    \n",
    "    if url == None:\n",
    "        return\n",
    "    field = {}\n",
    "    html = get_page(url)\n",
    "    if html == None:\n",
    "        return\n",
    "    tree = lhtml.fromstring(html.text)\n",
    "    \n",
    "    field[\"ID\"] = tree.xpath('//span[@itemprop=\"sku\"]')\n",
    "    field[\"ID\"] = field[\"ID\"][0].text if field[\"ID\"] else None\n",
    "    field[\"URL\"] = url\n",
    "    field[\"Название\"] = tree.xpath('//h1[@class=\"rd-page-product__title\"]//text()')\n",
    "    field[\"Название\"] = field[\"Название\"][0] if field[\"Название\"] else None\n",
    "    field[\"Автор\"] = tree.xpath('//a[@itemprop=\"brand\"]//text()')\n",
    "    field[\"Автор\"] = field[\"Автор\"][0] if field[\"Автор\"] else None\n",
    "    \n",
    "    preview_path = tree.xpath('//a[@class=\"download-pdf\"]')\n",
    "    field[\"Превью\"] = \"https://www.respublica.ru\" + preview_path[0].attrib['href'] if preview_path else None\n",
    "    \n",
    "    field[\"Изображение\"] = tree.xpath('//meta[@property=\"og:image\"]')\n",
    "    field[\"Изображение\"] = field[\"Изображение\"][0].attrib['content'] if field[\"Изображение\"] else None\n",
    "    field[\"Описание\"] = tree.xpath('//div[@class=\"rd-page-product__desc-body\"]//text()')\n",
    "    field[\"Описание\"] = ' '.join(field[\"Описание\"]) if field[\"Описание\"] else None\n",
    "    field[\"Цена\"] = tree.xpath('//span[@class=\"num\"]//text()')\n",
    "    field[\"Цена\"] = int(field[\"Цена\"][0].replace(' ','')) if field[\"Цена\"] else None\n",
    "    \n",
    "    field[\"Цена (старая)\"] = tree.xpath('//div[@class=\"rd-page-product__price-old\"]//span//text()')\n",
    "    field[\"Цена (старая)\"] = field[\"Цена (старая)\"][0] if field[\"Цена (старая)\"] else None\n",
    "    \n",
    "    field[\"В наличии\"] = bool(tree.xpath('//a[@class=\"rd-page-product__buy rd-page-product__buy_status_available\"]'))\n",
    "    \n",
    "    categories = tree.xpath('//div[@class=\"rd-page-breadcrumbs rd-page-product__breadcrumbs\"]//span[@itemprop=\"name\"]//text()')\n",
    "    field[\"Категория\"] = '; '.join([item[1:] for item in categories]) if categories else None\n",
    "    \n",
    "    rating_block = tree.xpath('//span[@itemprop=\"aggregateRating\"]')\n",
    "    \n",
    "    if rating_block:\n",
    "        \n",
    "        field[\"Число отзывов\"] = rating_block[0].xpath('//meta[@itemprop=\"reviewCount\"]')       \n",
    "        field[\"Число отзывов\"] = int(field[\"Число отзывов\"][0].attrib['content']) if field[\"Число отзывов\"] else None\n",
    "        field[\"Число оценок\"] = rating_block[0].xpath('//meta[@itemprop=\"ratingCount\"]')\n",
    "        field[\"Число оценок\"] = int(field[\"Число оценок\"][0].attrib['content']) if field[\"Число оценок\"] else None\n",
    "        field[\"Оценка\"] = rating_block[0].xpath('//meta[@itemprop=\"ratingValue\"]')\n",
    "        field[\"Оценка\"] = float(field[\"Оценка\"][0].attrib['content']) if field[\"Оценка\"] else None\n",
    "    \n",
    "    table = tree.xpath('//p[@class=\"rd-page-product__desc-param\"]')\n",
    "    table = table[0] if table else None\n",
    "\n",
    "    names  = table.xpath('.//span[@itemprop=\"name\"]/text()')\n",
    "    values = table.xpath('.//*[@itemprop=\"value\"]/text()')\n",
    "    field.update(zip(names, values))  \n",
    "\n",
    "    return field\n",
    "\n",
    "@exception_counter\n",
    "def get_site_wrapper(uid):\n",
    "    \n",
    "    try:    \n",
    "        result = get_site(uid)\n",
    "    except ex:\n",
    "        raise(ex)\n",
    "    \n",
    "    with mutex:\n",
    "        \n",
    "        global n_processed\n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with ThreadPool(100) as pool:\n",
    "    all_sites = pool.map(get_site_wrapper, url_history_for_download)\n",
    "pool.join()\n",
    "print(\"\\n%i\" % get_site_wrapper.ex_count, \"pages couldn't be load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = [site for site in all_sites if site] # Фильтруем от Nane'ов - сайтов, которые не получилось скачать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.DataFrame(all_sites)\n",
    "sites.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.to_csv('d.harazyan_hw_3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
